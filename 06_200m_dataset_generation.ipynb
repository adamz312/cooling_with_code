{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xq-tzPDRiDT"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcTL174RiDT"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JClgwHwrRiDU"
      },
      "source": [
        "Ignore if not using Google Collab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B-DyaJlyRiDU",
        "outputId": "3fc69fe5-f55d-481b-9a38-6e8e1e980278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n",
            "fatal: destination path 'cooling_with_code' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/cooling_with_code\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount google drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive\n",
        "!git clone https://github.com/FranciscoLozCoding/cooling_with_code.git\n",
        "%cd cooling_with_code\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPhTYV7RiDU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download libraries not in google collab (can be disregarded if not using collab)"
      ],
      "metadata": {
        "id": "cy34Gb82o2WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install stackstac\n",
        "%pip install pystac-client\n",
        "%pip install planetary-computer\n",
        "%pip install odc-stac\n",
        "%pip install rioxarray\n",
        "%pip install geopandas\n",
        "%pip install geopy\n",
        "%pip install folium"
      ],
      "metadata": {
        "id": "W5wClmb6o2r3",
        "outputId": "47fcbfb1-8b90-41ed-c0db-e0b521779539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stackstac\n",
            "  Downloading stackstac-0.5.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting dask>=2022.1.1 (from dask[array]>=2022.1.1->stackstac)\n",
            "  Downloading dask-2025.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy<3,>1.23 in /usr/local/lib/python3.11/dist-packages (from stackstac) (1.26.4)\n",
            "Requirement already satisfied: pandas<3,>=2 in /usr/local/lib/python3.11/dist-packages (from stackstac) (2.2.2)\n",
            "Collecting pyproj<4.0.0,>=3.0.0 (from stackstac)\n",
            "  Downloading pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting rasterio<2.0.0,>=1.3.0 (from stackstac)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting xarray>=0.18 (from stackstac)\n",
            "  Downloading xarray-2025.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (2025.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (24.2)\n",
            "Collecting partd>=1.4.0 (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac)\n",
            "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (1.0.0)\n",
            "Collecting importlib_metadata>=4.13.0 (from dask>=2022.1.1->dask[array]>=2022.1.1->stackstac)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=2->stackstac) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=2->stackstac) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=2->stackstac) (2025.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj<4.0.0,>=3.0.0->stackstac) (2025.1.31)\n",
            "Collecting affine (from rasterio<2.0.0,>=1.3.0->stackstac)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio<2.0.0,>=1.3.0->stackstac) (25.1.0)\n",
            "Collecting cligj>=0.5 (from rasterio<2.0.0,>=1.3.0->stackstac)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio<2.0.0,>=1.3.0->stackstac)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio<2.0.0,>=1.3.0->stackstac) (3.2.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2022.1.1->dask[array]>=2022.1.1->stackstac) (3.21.0)\n",
            "Collecting locket (from partd>=1.4.0->dask>=2022.1.1->dask[array]>=2022.1.1->stackstac)\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2->stackstac) (1.17.0)\n",
            "Downloading stackstac-0.5.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask-2025.2.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xarray-2025.1.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: pyproj, locket, importlib_metadata, cligj, click-plugins, affine, rasterio, partd, xarray, dask, stackstac\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 dask-2025.2.0 importlib_metadata-8.6.1 locket-1.0.0 partd-1.4.2 pyproj-3.7.1 rasterio-1.4.3 stackstac-0.5.1 xarray-2025.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "bb7515b0999f4154b5e260bde68de79c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pystac-client\n",
            "  Downloading pystac_client-0.8.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: requests>=2.28.2 in /usr/local/lib/python3.11/dist-packages (from pystac-client) (2.32.3)\n",
            "Collecting pystac>=1.10.0 (from pystac[validation]>=1.10.0->pystac-client)\n",
            "  Downloading pystac-1.12.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pystac-client) (2.9.0.post0)\n",
            "Requirement already satisfied: jsonschema~=4.18 in /usr/local/lib/python3.11/dist-packages (from pystac[validation]>=1.10.0->pystac-client) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pystac-client) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.2->pystac-client) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (4.12.2)\n",
            "Downloading pystac_client-0.8.6-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystac-1.12.2-py3-none-any.whl (194 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m184.3/194.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pystac, pystac-client\n",
            "Successfully installed pystac-1.12.2 pystac-client-0.8.6\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "^C\n",
            "^C\n",
            "^C\n",
            "Collecting rioxarray\n",
            "  Downloading rioxarray-0.18.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from rioxarray) (24.2)\n",
            "Requirement already satisfied: rasterio>=1.3.7 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (1.4.3)\n",
            "Requirement already satisfied: xarray>=2024.7.0 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (2025.1.2)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from rioxarray) (1.26.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3->rioxarray) (2025.1.31)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (25.1.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio>=1.3.7->rioxarray) (3.2.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray>=2024.7.0->rioxarray) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray>=2024.7.0->rioxarray) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray>=2024.7.0->rioxarray) (1.17.0)\n",
            "Downloading rioxarray-0.18.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h^C\n",
            "Collecting geopandas\n",
            "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from geopandas) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vl1L4fDRiDV"
      },
      "outputs": [],
      "source": [
        "#data science\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "#custom tools for this project\n",
        "from tools.environment import VALID_SPLIT, RANDOM_STATE\n",
        "from tools.build_dataset import (\n",
        "    generate_buffer_dataset,\n",
        "    generate_median,\n",
        "    generate_building_gdf,\n",
        "    generate_traffic,\n",
        "    generate_weather_data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8KLaq6zRiDV"
      },
      "source": [
        "# Generating a 200m Buffer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsWVEezNRiDV"
      },
      "source": [
        "This notebook is for generating a new dataset using 200m Buffer Zones. After doing [04_EDA](/04_EDA.ipynb) we found that increasing the buffer zone from 150m to a value between 200m and 400m it might help our models capture the relationship between vegeatation and UHI better. For details on the features and how we generate our datasets see our past notebooks:\n",
        "- [01_dataset_generation](/01_dataset_generation.ipynb)\n",
        "- [02_more_dataset_generation](/02_more_dataset_generation.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">NOTE: we will use our custom tools here, for a in-depth explanation of these tools see the notebooks above."
      ],
      "metadata": {
        "id": "CgLn35i_fJCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_radius = 100  # radius in meters (diameter will be 200)"
      ],
      "metadata": {
        "id": "gK9W9Inxl1PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Dataset"
      ],
      "metadata": {
        "id": "p4UX1KDajdNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first create the training dataset."
      ],
      "metadata": {
        "id": "Lo1CbHTdnVPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the satellite image median.\n",
        "median = generate_median()\n",
        "\n",
        "# Generate the building geodataframe.\n",
        "buildings_gdf = generate_building_gdf()\n",
        "\n",
        "# Generate traffic data for UHI geodataframe.\n",
        "uhi_gdf = generate_traffic()\n",
        "\n",
        "# Read values into a series\n",
        "uhi = uhi_gdf['UHI Index'].values\n",
        "traffic_volume = uhi_gdf['traffic_volume'].values\n",
        "latitudes = uhi_gdf['Latitude'].values\n",
        "longitudes = uhi_gdf['Longitude'].values\n",
        "datetimes = uhi_gdf['datetime'].values\n",
        "\n",
        "# Apply Buffer Zone\n",
        "train_df = generate_buffer_dataset(\n",
        "    latitudes, longitudes,\n",
        "    buffer_radius, traffic_volume,\n",
        "    median, buildings_gdf,\n",
        "    UHI=uhi, datetimes=datetimes)\n",
        "\n",
        "# Add the weather data\n",
        "train_df = generate_weather_data(train_df)\n",
        "\n",
        "# remove cols we dont need\n",
        "cols = ['Latitude', 'Longitude', 'datetime']\n",
        "train_df.drop(cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "8fkI70Bji2B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show features\n",
        "train_df.describe()"
      ],
      "metadata": {
        "id": "1gDkX8bAjt_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to csv file\n",
        "train_df.to_csv(f\"{buffer_radius*2}m_buffer_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "TrggfKQGj0T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Dataset"
      ],
      "metadata": {
        "id": "IAZGh_f-jfKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create our testing dataset."
      ],
      "metadata": {
        "id": "8VtgBn-mnZiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#csv path for target variable for testing dataset\n",
        "test_csv = \"data/Testing_data_uhi_index.csv\"\n",
        "\n",
        "# Generate traffic data for UHI geodataframe.\n",
        "test_uhi_df = generate_traffic(uhi_csv_file=\"data/Testing_data_uhi_index.csv\")\n",
        "\n",
        "# Read values into a series\n",
        "traffic_volume = test_uhi_df['traffic_volume'].values\n",
        "latitudes = test_uhi_df['Latitude'].values\n",
        "longitudes = test_uhi_df['Longitude'].values\n",
        "\n",
        "# Apply Buffer Zone\n",
        "test_df = generate_buffer_dataset(\n",
        "    latitudes, longitudes,\n",
        "    buffer_radius, traffic_volume,\n",
        "    median, buildings_gdf)\n",
        "\n",
        "# Add the weather data\n",
        "test_df = generate_weather_data(test_df)\n",
        "\n",
        "# drop variables we dont need\n",
        "# NOTE: We need the lat and lon here, since they are required in the final submission\n",
        "cols = ['datetime', 'UHI']\n",
        "test_df.drop(cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "5iZX04Nzj-S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show features\n",
        "test_df.describe()"
      ],
      "metadata": {
        "id": "MHKgTIMalnPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to csv file\n",
        "test_df.to_csv(f\"{buffer_radius*2}m_buffer_test_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "Kepgl9UPlroq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Eputof9RiDV"
      },
      "source": [
        "# Evaluating the 200m Buffer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's evaluate how this new dataset does on a simple RandomForestRegressor."
      ],
      "metadata": {
        "id": "i1__oKYRncBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = train_df.copy()\n",
        "\n",
        "# Scale data using standardscaler\n",
        "sc = StandardScaler()\n",
        "scaled_dataset = sc.fit_transform(dataset)\n",
        "\n",
        "# Convert back to a DataFrame with original columns and index\n",
        "dataset = pd.DataFrame(scaled_dataset, columns=dataset.columns, index=dataset.index)\n",
        "\n",
        "# Split the data into features (X) and target (y), and then into training and validation sets\n",
        "x = dataset.drop(columns=['UHI']).values\n",
        "y = dataset['UHI'].values\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    x, y,\n",
        "    test_size=VALID_SPLIT,\n",
        "    random_state=RANDOM_STATE)\n",
        "x_names = list(dataset.drop(columns=['UHI']).columns)\n",
        "\n",
        "# Train the Random Forest model on the training data\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=RANDOM_STATE,\n",
        "    criterion=\"squared_error\")\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "insample_predictions = rf_model.predict(x_train)\n",
        "\n",
        "# calculate R-squared score for in-sample predictions\n",
        "print(f\"In-Sample Evaluation:\")\n",
        "insample_r2 = r2_score(y_train, insample_predictions)\n",
        "print(f\"  R-squared: {insample_r2}\")\n",
        "\n",
        "# Make predictions on the validation data\n",
        "out_of_sample_predictions = rf_model.predict(x_valid)\n",
        "\n",
        "# calculate R-squared score for out-sample predictions\n",
        "print(f\"Out-Of-Sample Evaluation:\")\n",
        "out_of_sample_r2 = r2_score(y_valid, out_of_sample_predictions)\n",
        "print(f\"  R-squared: {out_of_sample_r2}\")"
      ],
      "metadata": {
        "id": "5LVMGu2Wm0we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf3rgvoZRiDV"
      },
      "source": [
        ">TODO: Create a simple RF regressor and compare to 150m simple RF regressor"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}